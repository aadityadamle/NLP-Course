{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS Tagging",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadityadamle/NLP-Course/blob/main/POS_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXDqVfhOrSla"
      },
      "source": [
        "# Add a news item here and tag few words in it. This would tell the user what is achieved at the end and what is he going to learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrB8Q-AQxujT"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sillWAB8yNID",
        "outputId": "4fe82d4e-94d9-4693-a868-1f683f71f2cc"
      },
      "source": [
        "nltk.download(\"book\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5GQd7Q4w3Km"
      },
      "source": [
        "# POS - Tagging\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZajsbiP8ng7"
      },
      "source": [
        "Part-of-Speech tagging is used like a intermediate step to simplify a lot of different NLP problems. The major issue which is an obstacle for many NLP tasks is ambiguity in text. \n",
        "\n",
        "Ambiguity in text occurs when the meaning of the text is not known or it's meaning is uncertain depending on the context. For example, **\"I left my phone on the left side of the room.\"**\n",
        "\n",
        "In the above sentence the word \"left\" depicts action and positon as well. NLP systems have to correctly identify which \"left\" represents action and which showcases position. This is just one simple example of ambiguous text from the many types of ambiguities. So POS tagging can effectively identify the purpose of every token in a given text (position or action here) making the job a bit simpler.    \n",
        "\n",
        "Part-of-speech tagging is a process of  attaching a part of speech tag to each word in the sequence of words. Parts of speech are also known as word classes or lexical categories. The collection of tags used for a particular task is known as a tagset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0cac6mj0U2d"
      },
      "source": [
        "The below code shows an example of a basic tagging operation on the above example.  The text should be tokenized before applying any tagging operaions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvCQ8ziswvfP",
        "outputId": "9d69025d-2be9-481e-c939-cd300184612f"
      },
      "source": [
        "text = nltk.word_tokenize(\"I left my phone on the left side of the room.\")\n",
        "tagged_text = nltk.pos_tag(text)\n",
        "tagged_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('left', 'VBD'),\n",
              " ('my', 'PRP$'),\n",
              " ('phone', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('left', 'JJ'),\n",
              " ('side', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('room', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GEBJj5nw3IC"
      },
      "source": [
        "The output of tagging gives different types of labels also called as tags to the words in the text. Observe that two different instances of the word \"left\" have different tags. First instance has \"VBD\" tag which means \"Past Action\" and the second instance has \"JJ\" tag which means \"Adjective\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pdU3gbEova"
      },
      "source": [
        "# Use of POS tagging:\n",
        "\n",
        "By simplifying such ambiguities POS tagging helps to solve many tasks. It is widely used in text-to-speech applications to pronounce the words with same spelling differently based on the context or purpose. \n",
        "\n",
        "For example, \"He's got to polish up his Polish for his job.\" \n",
        "\n",
        "Here the first instance of the word \"Polish\" means **to refine or improve**  and the second instance means the **language of Poland**. The beginning of former is pronound similarly as \"**Po**t\" and the later is pronound similar to \"**Po**et\".\n",
        "\n",
        "Below code shows the different tags:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WBTUFXzdpTc",
        "outputId": "3137fac6-fb1f-4c01-e133-b3613bd8afd0"
      },
      "source": [
        "text = nltk.word_tokenize(\"He's got to polish up his Polish for his job.\")\n",
        "tagged_text = nltk.pos_tag(text)\n",
        "tagged_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He', 'PRP'),\n",
              " (\"'s\", 'VBZ'),\n",
              " ('got', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('polish', 'VB'),\n",
              " ('up', 'RP'),\n",
              " ('his', 'PRP$'),\n",
              " ('Polish', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('his', 'PRP$'),\n",
              " ('job', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaXRzcB-iUEw"
      },
      "source": [
        "The difference is lucid after tagging the words. First instance is a verb and second is a noun."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN_TfuW6hs6Y"
      },
      "source": [
        "Imagine a question answering system which gives wrong answers just because it gets confused with meanings of such words. POS tagging is the answer to this problem as well. \n",
        "\n",
        "For example, \"Who will play with the dog while they are at the play?\" \n",
        "\n",
        "Here the first instance of the word \"Play\" represents **action**  and the second instance means the **art form**.  Now humans can figure out this difference very easily and know the meanings of both instances correctly because of the beauty of our mind. But NLP systems may get confused in such simple scenarios as well.\n",
        "\n",
        "Below code shows the different tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nypfY9IdpIa",
        "outputId": "5e4e4ada-1ef5-44b8-acdf-2c774af6ebff"
      },
      "source": [
        "text = nltk.word_tokenize(\"Who will play with the dog while they are at the play?\")\n",
        "tagged_text = nltk.pos_tag(text)\n",
        "tagged_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Who', 'WP'),\n",
              " ('will', 'MD'),\n",
              " ('play', 'VB'),\n",
              " ('with', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('dog', 'NN'),\n",
              " ('while', 'IN'),\n",
              " ('they', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('play', 'NN'),\n",
              " ('?', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2swGiH6lpq8"
      },
      "source": [
        "After tagging the words we get to know that first instance is a verb and second is a noun."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69neRWukdwZh"
      },
      "source": [
        "Numerous such applications where natural language is used will require POS tagging to remove ambiguities.\n",
        "\n",
        "Now that you know the crucial role of POS tagging in NLP tasks we will start with learning the different initial taggers which are the base for current very effective tagger classes. We will learn the basic idea behind design and working of some taggers provided by NLTK. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZBAsXBAw3Fa"
      },
      "source": [
        "POS taggers fall into two groups mainly:\n",
        "\n",
        "\n",
        "1.   Rule-Based POS Taggers\n",
        "2.   Stochastic POS Taggers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0OxPJ_79ijR"
      },
      "source": [
        "# Rule - based Taggers\n",
        "Rule - based Taggers use a set of predefined rules which they follow to tag the words in the text. These rules are based on contextual information to assign tags to unknown or ambiguous words. Contextual information contains the knowledge of POS of the words preceding or following the ambiguous word. For example, if the preceding word is an adverb, then the word in question must be a verb. This information is coded in the form of a rule as follows:\n",
        "\n",
        "If an ambiguous word is preceded by an adverb,  tag it as a verb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX6KDnCrea9Z"
      },
      "source": [
        "\n",
        "The simplest possible tagger is a default tagger which assigns every token with the same tag. It initiates a baseline for taggers. \n",
        "\n",
        "## Regular Expression Tagger:\n",
        "\n",
        "The next tagger labels the tokens on the basis of matching patterns. These patterns are used to identify various POS. For example, any word ending in ed is the past participle of a verb, and any word ending with 's is a possessive noun. \n",
        "\n",
        "These patterns are matched with the token using regular expressions and hence the name is Regular Expression Tagger. The following code shows the implementation of regular expression tagger:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ipEAKviMf6"
      },
      "source": [
        "# Importing the sentences and tagged sentences from brown corpus for tagging and\n",
        "# checking the accuracy\n",
        " \n",
        "from nltk.corpus import brown\n",
        "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
        "brown_sents = brown.sents(categories='news')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzEZwn02eazh"
      },
      "source": [
        "# Define the patterns and corresponding tags for every POS\n",
        "patterns = [\n",
        "            (r'.*ing$', 'VBG'),                # gerunds\n",
        "            (r'.*ed$', 'VBD'),                 # simple past\n",
        "            (r'.*es$', 'VBZ'),                 # 3rd singular present\n",
        "            (r'.*ould$', 'MD'),                # modals\n",
        "            (r'.*\\'s$', 'NN$'),                # possessive nouns\n",
        "            (r'.*s$', 'NNS'),                  # plural nouns\n",
        "            (r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
        "            (r'.*', 'NN')]                      # nouns (default)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uWo_9ODeaiR",
        "outputId": "eca622c8-9ec7-46c1-9f6e-a6b80deee6fa"
      },
      "source": [
        "regexp_tagger = nltk.RegexpTagger(patterns)\n",
        "regexp_tagger.tag(brown_sents[50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'NN'),\n",
              " ('largest', 'NN'),\n",
              " ('hurdle', 'NN'),\n",
              " ('the', 'NN'),\n",
              " ('Republicans', 'NNS'),\n",
              " ('would', 'MD'),\n",
              " ('have', 'NN'),\n",
              " ('to', 'NN'),\n",
              " ('face', 'NN'),\n",
              " ('is', 'NNS'),\n",
              " ('a', 'NN'),\n",
              " ('state', 'NN'),\n",
              " ('law', 'NN'),\n",
              " ('which', 'NN'),\n",
              " ('says', 'NNS'),\n",
              " ('that', 'NN'),\n",
              " ('before', 'NN'),\n",
              " ('making', 'VBG'),\n",
              " ('a', 'NN'),\n",
              " ('first', 'NN'),\n",
              " ('race', 'NN'),\n",
              " (',', 'NN'),\n",
              " ('one', 'NN'),\n",
              " ('of', 'NN'),\n",
              " ('two', 'NN'),\n",
              " ('alternative', 'NN'),\n",
              " ('courses', 'VBZ'),\n",
              " ('must', 'NN'),\n",
              " ('be', 'NN'),\n",
              " ('taken', 'NN'),\n",
              " (':', 'NN'),\n",
              " ('1', 'CD')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sdfEgTUeaeo",
        "outputId": "85d3883f-551d-43e3-ced3-ec279ecaebd7"
      },
      "source": [
        "regexp_tagger.evaluate(brown_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20186168625812995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQc8FhaWKI0"
      },
      "source": [
        "As you can observe in the output above the most of the tokens are tagged as nouns. This is because of the last condition which in the patterns. So if the token does not match with above patterns then that token is automatically tagged as noun by default. As the tagger contains limited number of patterns or tags there are many tokens which are void of being correctly tagged and thus the accuracy is very less."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiElkg96WKF5"
      },
      "source": [
        "## The Lookup Tagger:\n",
        "\n",
        "As you saw the previous tagger had a very low accuracy and many tokens had noun tags which means many tokens did not match to any of the pattern and tags. But what if we knew the tags of the frequently occuring words in the text? Then we will be able to tag many tokens with there corresponding tags because we had known these tags previously. This is called as lookup tagging. \n",
        "\n",
        "Firstly, let's find the hundred most frequent words and store their most likely tag. We can then use this information as the model for a \"lookup tagger\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rr0D9q_WJ4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0131158-ffd6-4088-d85e-13bbd3cad1f3"
      },
      "source": [
        "# Creating a frequency distribution of the word corpus \n",
        "fd = nltk.FreqDist(brown.words(categories='news'))\n",
        "\n",
        "# Frequency Distribution of the tags with words. This computes which tag is used \n",
        "#  how many times for a particular word. \n",
        "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
        "\n",
        "# Selecting 100 most common words from FreqDist \n",
        "most_freq_words = fd.most_common(100)\n",
        "\n",
        "# Selecting most frequent tag for every word in top 100 words\n",
        "likely_tags = dict((word, cfd[word].max()) for (word, _) in most_freq_words)\n",
        "\n",
        "# Creating a lookup tagger using the most common words with their most likely tags\n",
        "lookup_tagger = nltk.UnigramTagger(model=likely_tags)\n",
        "\n",
        "# Evaluating the accuracy of the tagger\n",
        "lookup_tagger.evaluate(brown_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45578495136941344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hElsqD8rhphW"
      },
      "source": [
        "The accuracy of theis tagger is better than the Regular Expression tagger. But this is only because the words in the corpus are known to the tagger. If used over unseen data the tagger performs poorly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4NazbVXiFgN",
        "outputId": "f296045d-b012-448a-f41d-8c2185fb6fda"
      },
      "source": [
        "sent = brown.sents(categories='news')[3]\n",
        "lookup_tagger.tag(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('``', '``'),\n",
              " ('Only', None),\n",
              " ('a', 'AT'),\n",
              " ('relative', None),\n",
              " ('handful', None),\n",
              " ('of', 'IN'),\n",
              " ('such', None),\n",
              " ('reports', None),\n",
              " ('was', 'BEDZ'),\n",
              " ('received', None),\n",
              " (\"''\", \"''\"),\n",
              " (',', ','),\n",
              " ('the', 'AT'),\n",
              " ('jury', None),\n",
              " ('said', 'VBD'),\n",
              " (',', ','),\n",
              " ('``', '``'),\n",
              " ('considering', None),\n",
              " ('the', 'AT'),\n",
              " ('widespread', None),\n",
              " ('interest', None),\n",
              " ('in', 'IN'),\n",
              " ('the', 'AT'),\n",
              " ('election', None),\n",
              " (',', ','),\n",
              " ('the', 'AT'),\n",
              " ('number', None),\n",
              " ('of', 'IN'),\n",
              " ('voters', None),\n",
              " ('and', 'CC'),\n",
              " ('the', 'AT'),\n",
              " ('size', None),\n",
              " ('of', 'IN'),\n",
              " ('this', 'DT'),\n",
              " ('city', None),\n",
              " (\"''\", \"''\"),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQQmSFRTiaZQ"
      },
      "source": [
        "As I said before when tried over unseen data many unknown words are tagged as \"None\". A technique that was used in the Regular Expression tagger can be used here to eliminate this \"None\" tag. If a token does not get tagged with the list of most common tags then automatically assign the \"Noun\" tag to the word by default. This technique is called as Backoff.       "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7HiJVQMkDqu",
        "outputId": "e27aa03b-a630-441c-a5cd-7f35355f3d18"
      },
      "source": [
        "lookup_tagger = nltk.UnigramTagger(model=likely_tags,\n",
        "                                     backoff=nltk.DefaultTagger('NN'))\n",
        "sent = brown.sents(categories='news')[3]\n",
        "lookup_tagger.tag(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('``', '``'),\n",
              " ('Only', 'NN'),\n",
              " ('a', 'AT'),\n",
              " ('relative', 'NN'),\n",
              " ('handful', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('such', 'NN'),\n",
              " ('reports', 'NN'),\n",
              " ('was', 'BEDZ'),\n",
              " ('received', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " (',', ','),\n",
              " ('the', 'AT'),\n",
              " ('jury', 'NN'),\n",
              " ('said', 'VBD'),\n",
              " (',', ','),\n",
              " ('``', '``'),\n",
              " ('considering', 'NN'),\n",
              " ('the', 'AT'),\n",
              " ('widespread', 'NN'),\n",
              " ('interest', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'AT'),\n",
              " ('election', 'NN'),\n",
              " (',', ','),\n",
              " ('the', 'AT'),\n",
              " ('number', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('voters', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('the', 'AT'),\n",
              " ('size', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('this', 'DT'),\n",
              " ('city', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PtG740_kS3j"
      },
      "source": [
        "You can compare and see the lucid difference. All \"None\" tags are replaced by noun tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iibVg8KkmeVj"
      },
      "source": [
        "# Stochastic Taggers\n",
        "\n",
        "The taggers which incorporate frequency or probability in the approch to solve the problem of POS tagging are called as Stochastic taggers. \n",
        "\n",
        "By using frequency or probability one can find out how many times a particular token is tagged by a POS. And based on all the frequncies the probability of a token having that particular POS tag can be calculated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tQVCNSSqNd9"
      },
      "source": [
        "## Unigram Tagger:\n",
        "\n",
        "Its the simplest stochastic tagger which disambiguate words based solely on the probability that a word occurs with a particular tag. The tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd_4kHyIsjF-",
        "outputId": "bb001520-0d42-4f3b-e366-7515d62b45c7"
      },
      "source": [
        "# Making split_size for training and testing sets\n",
        "split_size = int(len(brown_tagged_sents) * 0.9)\n",
        "split_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcJmDNaXsqWN"
      },
      "source": [
        "# Generating training and testing sets with split_size\n",
        "train_sents = brown_tagged_sents[:split_size]\n",
        "test_sents = brown_tagged_sents[split_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xF-NcnRqEms",
        "outputId": "e37acd73-2f80-47c5-d469-68d1c2d33ce7"
      },
      "source": [
        "# Using training set for learning\n",
        "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
        "# Checking the accuracy on test set\n",
        "unigram_tagger.evaluate(test_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8121200039868434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2POVxewqCmM"
      },
      "source": [
        "The accuracy is amaizing as compared to the previous taggers. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLkhaUmCp7sN"
      },
      "source": [
        "## Bigram Tagger (N-gram taggers):\n",
        "\n",
        "In this technique the probability of a given sequence of tags occurring is calculated. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. Bigram means considering 2 previous tags. This approach makes much more sense than the former because it considers the tags for individual words based on context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e_F7ieRsFus",
        "outputId": "5a2bc48b-61b2-4b3f-87cf-899c890059d0"
      },
      "source": [
        "# Learning and tagging from trainig set\n",
        "bigram_tagger = nltk.BigramTagger(train_sents)\n",
        "bigram_tagger.tag(brown_sents[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('800', 'CD'),\n",
              " ('in', 'IN'),\n",
              " ('Southern', 'JJ-TL'),\n",
              " ('New', 'JJ-TL'),\n",
              " ('England', 'NP'),\n",
              " (',', ','),\n",
              " ('we', 'PPSS'),\n",
              " ('have', 'HV'),\n",
              " ('60', 'CD'),\n",
              " (';', '.'),\n",
              " (';', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3vR7gMgtUIw",
        "outputId": "47e8b18a-f30b-4c25-da74-be4f8c95187b"
      },
      "source": [
        "# Checking the accuracy on test set\n",
        "bigram_tagger.evaluate(test_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10206319146815508"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vJkb7SwtC5D",
        "outputId": "977979ee-0db8-433a-ffcb-49319aa8220f"
      },
      "source": [
        "# Using tagger on unseen sentence\n",
        "unseen_sent = brown_sents[4500]\n",
        "bigram_tagger.tag(unseen_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Japan', None),\n",
              " (',', None),\n",
              " ('since', None),\n",
              " ('1957', None),\n",
              " (',', None),\n",
              " ('has', None),\n",
              " ('been', None),\n",
              " ('``', None),\n",
              " ('voluntarily', None),\n",
              " (\"''\", None),\n",
              " ('curbing', None),\n",
              " ('exports', None),\n",
              " ('of', None),\n",
              " ('textiles', None),\n",
              " ('to', None),\n",
              " ('the', None),\n",
              " ('U.S.', None),\n",
              " ('.', None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8M4UklvuqEq"
      },
      "source": [
        "As you can see using tagger on unseen data again yeilds unsatisfactory result with all \"None\" tags. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZy2OJYiggmx"
      },
      "source": [
        "## Reference :\n",
        "\n",
        "http://www.nltk.org/book/ch05.html\n",
        "\n",
        "https://www.freecodecamp.org/news/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24/"
      ]
    }
  ]
}